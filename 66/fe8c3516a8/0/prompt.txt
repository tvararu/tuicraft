Base directory for this skill: /home/openclaw/.claude/plugins/cache/claude-plugins-official/superpowers/4.3.1/skills/using-superpowers

<EXTREMELY-IMPORTANT>
If you think there is even a 1% chance a skill might apply to what you are doing, you ABSOLUTELY MUST invoke the skill.

IF A SKILL APPLIES TO YOUR TASK, YOU DO NOT HAVE A CHOICE. YOU MUST USE IT.

This is not negotiable. This is not optional. You cannot rationalize your way out of this.
</EXTREMELY-IMPORTANT>

## How to Access Skills

**In Claude Code:** Use the `Skill` tool. When you invoke a skill, its content is loaded and presented to you‚Äîfollow it directly. Never use the Read tool on skill files.

**In other environments:** Check your platform's documentation for how skills are loaded.

# Using Skills

## The Rule

**Invoke relevant or requested skills BEFORE any response or action.** Even a 1% chance a skill might apply means that you should invoke the skill to check. If an invoked skill turns out to be wrong for the situation, you don't need to use it.

```dot
digraph skill_flow {
    "User message received" [shape=doublecircle];
    "About to EnterPlanMode?" [shape=doublecircle];
    "Already brainstormed?" [shape=diamond];
    "Invoke brainstorming skill" [shape=box];
    "Might any skill apply?" [shape=diamond];
    "Invoke Skill tool" [shape=box];
    "Announce: 'Using [skill] to [purpose]'" [shape=box];
    "Has checklist?" [shape=diamond];
    "Create TodoWrite todo per item" [shape=box];
    "Follow skill exactly" [shape=box];
    "Respond (including clarifications)" [shape=doublecircle];

    "About to EnterPlanMode?" -> "Already brainstormed?";
    "Already brainstormed?" -> "Invoke brainstorming skill" [label="no"];
    "Already brainstormed?" -> "Might any skill apply?" [label="yes"];
    "Invoke brainstorming skill" -> "Might any skill apply?";

    "User message received" -> "Might any skill apply?";
    "Might any skill apply?" -> "Invoke Skill tool" [label="yes, even 1%"];
    "Might any skill apply?" -> "Respond (including clarifications)" [label="definitely not"];
    "Invoke Skill tool" -> "Announce: 'Using [skill] to [purpose]'";
    "Announce: 'Using [skill] to [purpose]'" -> "Has checklist?";
    "Has checklist?" -> "Create TodoWrite todo per item" [label="yes"];
    "Has checklist?" -> "Follow skill exactly" [label="no"];
    "Create TodoWrite todo per item" -> "Follow skill exactly";
}
```

## Red Flags

These thoughts mean STOP‚Äîyou're rationalizing:

| Thought | Reality |
|---------|---------|
| "This is just a simple question" | Questions are tasks. Check for skills. |
| "I need more context first" | Skill check comes BEFORE clarifying questions. |
| "Let me explore the codebase first" | Skills tell you HOW to explore. Check first. |
| "I can check git/files quickly" | Files lack conversation context. Check for skills. |
| "Let me gather information first" | Skills tell you HOW to gather information. |
| "This doesn't need a formal skill" | If a skill exists, use it. |
| "I remember this skill" | Skills evolve. Read current version. |
| "This doesn't count as a task" | Action = task. Check for skills. |
| "The skill is overkill" | Simple things become complex. Use it. |
| "I'll just do this one thing first" | Check BEFORE doing anything. |
| "This feels productive" | Undisciplined action wastes time. Skills prevent this. |
| "I know what that means" | Knowing the concept ‚â† using the skill. Invoke it. |

## Skill Priority

When multiple skills could apply, use this order:

1. **Process skills first** (brainstorming, debugging) - these determine HOW to approach the task
2. **Implementation skills second** (frontend-design, mcp-builder) - these guide execution

"Let's build X" ‚Üí brainstorming first, then implementation skills.
"Fix this bug" ‚Üí debugging first, then domain-specific skills.

## Skill Types

**Rigid** (TDD, debugging): Follow exactly. Don't adapt away discipline.

**Flexible** (patterns): Adapt principles to context.

The skill itself tells you which.

## User Instructions

Instructions say WHAT, not HOW. "Add X" or "Fix Y" doesn't mean skip workflows.

---

Add DND and AFK status commands. /dnd [message] sends CMSG_CHAT_SET_DND (opcode from wow_messages reference), /afk [message] sends CMSG_CHAT_SET_AFK. Receiving is already handled since they come as chat message types. Follow the same pattern as say/yell/emote. Branch, implement with full test coverage, open a PR. Use feat: prefix for commits. Don't ask questions.

---

Base directory for this skill: /home/openclaw/.claude/plugins/cache/claude-plugins-official/superpowers/4.3.1/skills/brainstorming

# Brainstorming Ideas Into Designs

## Overview

Help turn ideas into fully formed designs and specs through natural collaborative dialogue.

Start by understanding the current project context, then ask questions one at a time to refine the idea. Once you understand what you're building, present the design and get user approval.

<HARD-GATE>
Do NOT invoke any implementation skill, write any code, scaffold any project, or take any implementation action until you have presented a design and the user has approved it. This applies to EVERY project regardless of perceived simplicity.
</HARD-GATE>

## Anti-Pattern: "This Is Too Simple To Need A Design"

Every project goes through this process. A todo list, a single-function utility, a config change ‚Äî all of them. "Simple" projects are where unexamined assumptions cause the most wasted work. The design can be short (a few sentences for truly simple projects), but you MUST present it and get approval.

## Checklist

You MUST create a task for each of these items and complete them in order:

1. **Explore project context** ‚Äî check files, docs, recent commits
2. **Ask clarifying questions** ‚Äî one at a time, understand purpose/constraints/success criteria
3. **Propose 2-3 approaches** ‚Äî with trade-offs and your recommendation
4. **Present design** ‚Äî in sections scaled to their complexity, get user approval after each section
5. **Write design doc** ‚Äî save to `docs/plans/YYYY-MM-DD-<topic>-design.md` and commit
6. **Transition to implementation** ‚Äî invoke writing-plans skill to create implementation plan

## Process Flow

```dot
digraph brainstorming {
    "Explore project context" [shape=box];
    "Ask clarifying questions" [shape=box];
    "Propose 2-3 approaches" [shape=box];
    "Present design sections" [shape=box];
    "User approves design?" [shape=diamond];
    "Write design doc" [shape=box];
    "Invoke writing-plans skill" [shape=doublecircle];

    "Explore project context" -> "Ask clarifying questions";
    "Ask clarifying questions" -> "Propose 2-3 approaches";
    "Propose 2-3 approaches" -> "Present design sections";
    "Present design sections" -> "User approves design?";
    "User approves design?" -> "Present design sections" [label="no, revise"];
    "User approves design?" -> "Write design doc" [label="yes"];
    "Write design doc" -> "Invoke writing-plans skill";
}
```

**The terminal state is invoking writing-plans.** Do NOT invoke frontend-design, mcp-builder, or any other implementation skill. The ONLY skill you invoke after brainstorming is writing-plans.

## The Process

**Understanding the idea:**
- Check out the current project state first (files, docs, recent commits)
- Ask questions one at a time to refine the idea
- Prefer multiple choice questions when possible, but open-ended is fine too
- Only one question per message - if a topic needs more exploration, break it into multiple questions
- Focus on understanding: purpose, constraints, success criteria

**Exploring approaches:**
- Propose 2-3 different approaches with trade-offs
- Present options conversationally with your recommendation and reasoning
- Lead with your recommended option and explain why

**Presenting the design:**
- Once you believe you understand what you're building, present the design
- Scale each section to its complexity: a few sentences if straightforward, up to 200-300 words if nuanced
- Ask after each section whether it looks right so far
- Cover: architecture, components, data flow, error handling, testing
- Be ready to go back and clarify if something doesn't make sense

## After the Design

**Documentation:**
- Write the validated design to `docs/plans/YYYY-MM-DD-<topic>-design.md`
- Use elements-of-style:writing-clearly-and-concisely skill if available
- Commit the design document to git

**Implementation:**
- Invoke the writing-plans skill to create a detailed implementation plan
- Do NOT invoke any other skill. writing-plans is the next step.

## Key Principles

- **One question at a time** - Don't overwhelm with multiple questions
- **Multiple choice preferred** - Easier to answer than open-ended when possible
- **YAGNI ruthlessly** - Remove unnecessary features from all designs
- **Explore alternatives** - Always propose 2-3 approaches before settling
- **Incremental validation** - Present design, get approval before moving on
- **Be flexible** - Go back and clarify when something doesn't make sense

---

Base directory for this skill: /home/openclaw/code/tuicraft/.claude/skills/typescript-style

# TypeScript Style

Prettier with defaults handles formatting.
This covers structure and taste.

## Types

- `type` only. No `interface`, no `enum`.
- `as const` objects for opcode tables and constant maps.
- Unions for enumerations: `type Status = "active" | "pending"`
- Never `any`. Reserve `unknown` for true boundaries. If you know the type, use
  it.
- Discriminated unions over loose fields. `UserEntry | AgentEntry` not `{ data:
unknown }`.
- Compose types with `&` for extending, but prefer nested fields over flat
  intersections when callers pass a shared object. Spread objects bypass
  TypeScript's excess property checks ‚Äî nesting preserves them.
- When 3+ functions share the same args, extract a context type and pass it as a
  nested field rather than repeating individual args at every call site.
- Extract types to keep function signatures to one line.
- Annotate params and return types. Skip the annotation when the type is inferred
  from a default value (`now = new Date()` not `now: Date = new Date()`).
- Absolute imports via baseUrl. No `.ts` extensions.

## Functions

- `function` for named/exported. Arrows for callbacks only.
- 3-10 lines ideal. 30 lines hard max.
- Never break an argument list across multiple lines. If Prettier would wrap the
  args, extract a type and take a single arg object instead.
- Destructure in the signature when it fits one line. Move to the body when it
  gets wide.
- Guards grouped at the top. Symmetry in sequential ifs.
- Build symmetrical helper pairs so call sites read like prose.
- Group related variables together at the top of the body.
- Functions should call their own dependencies ‚Äî don't make callers pass in what
  the function can get itself.
- Pull nested config objects into named variables above the call that uses them.
- Prefer template literals over `[...].join("\n")` for multi-line strings.

```ts
export function handle({ type, channel, user }: Event): string {
  if (!user) return "";
  if (type === "bot") return "";

  const sender = resolve(user);
  const formatted = formatFor(channel);

  return `${sender}: ${formatted}`;
}
```

## Classes

- Classes are fine for stateful protocol objects (ciphers, buffers, readers).
- Keep classes small and focused ‚Äî one responsibility.
- No inheritance. Compose instead.
- Export the class directly, not through a factory function.

## Control Flow

- Ternaries and `??` for simple binary choices. Never nest ternaries.
- `let` + if/else for three-way branches.
- Optimistic code. Let it throw. Don't catch errors around internal code whose
  preconditions you control.
- Only validate at system boundaries: user input, external APIs, network
  responses.

## Data and Organization

- Functional where possible. Plain objects and functions.
- `as const` for constant objects.
- Group related functions in one file (~50-200 lines).
- Co-locate related things. No scattering across dirs.
- No barrel files. Import from the source module.
- Almost never write comments.

## Naming

- Short, terse names for APIs and tools users will see.
- Suffix by kind when it clarifies: `sessionKey`, `realmHost`.
- If Prettier breaks a signature, the name is too long.
- Match field names to their destination so call sites use shorthand.
- Don't add config files when defaults work.

## Simplicity

- Getters should be pure. No side effects in functions that return values.
- Don't debounce, batch, or schedule what you can do synchronously in one call.
- Setup/wiring functions should be lean. Extract handlers, keep registration
  code to a list of one-liners.
- Aim for one-liner call sites. If an API call needs renaming args, the variable
  names are wrong.

---

Base directory for this skill: /home/openclaw/.claude/plugins/cache/claude-plugins-official/superpowers/4.3.1/skills/test-driven-development

# Test-Driven Development (TDD)

## Overview

Write the test first. Watch it fail. Write minimal code to pass.

**Core principle:** If you didn't watch the test fail, you don't know if it tests the right thing.

**Violating the letter of the rules is violating the spirit of the rules.**

## When to Use

**Always:**
- New features
- Bug fixes
- Refactoring
- Behavior changes

**Exceptions (ask your human partner):**
- Throwaway prototypes
- Generated code
- Configuration files

Thinking "skip TDD just this once"? Stop. That's rationalization.

## The Iron Law

```
NO PRODUCTION CODE WITHOUT A FAILING TEST FIRST
```

Write code before the test? Delete it. Start over.

**No exceptions:**
- Don't keep it as "reference"
- Don't "adapt" it while writing tests
- Don't look at it
- Delete means delete

Implement fresh from tests. Period.

## Red-Green-Refactor

```dot
digraph tdd_cycle {
    rankdir=LR;
    red [label="RED\nWrite failing test", shape=box, style=filled, fillcolor="#ffcccc"];
    verify_red [label="Verify fails\ncorrectly", shape=diamond];
    green [label="GREEN\nMinimal code", shape=box, style=filled, fillcolor="#ccffcc"];
    verify_green [label="Verify passes\nAll green", shape=diamond];
    refactor [label="REFACTOR\nClean up", shape=box, style=filled, fillcolor="#ccccff"];
    next [label="Next", shape=ellipse];

    red -> verify_red;
    verify_red -> green [label="yes"];
    verify_red -> red [label="wrong\nfailure"];
    green -> verify_green;
    verify_green -> refactor [label="yes"];
    verify_green -> green [label="no"];
    refactor -> verify_green [label="stay\ngreen"];
    verify_green -> next;
    next -> red;
}
```

### RED - Write Failing Test

Write one minimal test showing what should happen.

<Good>
```typescript
test('retries failed operations 3 times', async () => {
  let attempts = 0;
  const operation = () => {
    attempts++;
    if (attempts < 3) throw new Error('fail');
    return 'success';
  };

  const result = await retryOperation(operation);

  expect(result).toBe('success');
  expect(attempts).toBe(3);
});
```
Clear name, tests real behavior, one thing
</Good>

<Bad>
```typescript
test('retry works', async () => {
  const mock = jest.fn()
    .mockRejectedValueOnce(new Error())
    .mockRejectedValueOnce(new Error())
    .mockResolvedValueOnce('success');
  await retryOperation(mock);
  expect(mock).toHaveBeenCalledTimes(3);
});
```
Vague name, tests mock not code
</Bad>

**Requirements:**
- One behavior
- Clear name
- Real code (no mocks unless unavoidable)

### Verify RED - Watch It Fail

**MANDATORY. Never skip.**

```bash
npm test path/to/test.test.ts
```

Confirm:
- Test fails (not errors)
- Failure message is expected
- Fails because feature missing (not typos)

**Test passes?** You're testing existing behavior. Fix test.

**Test errors?** Fix error, re-run until it fails correctly.

### GREEN - Minimal Code

Write simplest code to pass the test.

<Good>
```typescript
async function retryOperation<T>(fn: () => Promise<T>): Promise<T> {
  for (let i = 0; i < 3; i++) {
    try {
      return await fn();
    } catch (e) {
      if (i === 2) throw e;
    }
  }
  throw new Error('unreachable');
}
```
Just enough to pass
</Good>

<Bad>
```typescript
async function retryOperation<T>(
  fn: () => Promise<T>,
  options?: {
    maxRetries?: number;
    backoff?: 'linear' | 'exponential';
    onRetry?: (attempt: number) => void;
  }
): Promise<T> {
  // YAGNI
}
```
Over-engineered
</Bad>

Don't add features, refactor other code, or "improve" beyond the test.

### Verify GREEN - Watch It Pass

**MANDATORY.**

```bash
npm test path/to/test.test.ts
```

Confirm:
- Test passes
- Other tests still pass
- Output pristine (no errors, warnings)

**Test fails?** Fix code, not test.

**Other tests fail?** Fix now.

### REFACTOR - Clean Up

After green only:
- Remove duplication
- Improve names
- Extract helpers

Keep tests green. Don't add behavior.

### Repeat

Next failing test for next feature.

## Good Tests

| Quality | Good | Bad |
|---------|------|-----|
| **Minimal** | One thing. "and" in name? Split it. | `test('validates email and domain and whitespace')` |
| **Clear** | Name describes behavior | `test('test1')` |
| **Shows intent** | Demonstrates desired API | Obscures what code should do |

## Why Order Matters

**"I'll write tests after to verify it works"**

Tests written after code pass immediately. Passing immediately proves nothing:
- Might test wrong thing
- Might test implementation, not behavior
- Might miss edge cases you forgot
- You never saw it catch the bug

Test-first forces you to see the test fail, proving it actually tests something.

**"I already manually tested all the edge cases"**

Manual testing is ad-hoc. You think you tested everything but:
- No record of what you tested
- Can't re-run when code changes
- Easy to forget cases under pressure
- "It worked when I tried it" ‚â† comprehensive

Automated tests are systematic. They run the same way every time.

**"Deleting X hours of work is wasteful"**

Sunk cost fallacy. The time is already gone. Your choice now:
- Delete and rewrite with TDD (X more hours, high confidence)
- Keep it and add tests after (30 min, low confidence, likely bugs)

The "waste" is keeping code you can't trust. Working code without real tests is technical debt.

**"TDD is dogmatic, being pragmatic means adapting"**

TDD IS pragmatic:
- Finds bugs before commit (faster than debugging after)
- Prevents regressions (tests catch breaks immediately)
- Documents behavior (tests show how to use code)
- Enables refactoring (change freely, tests catch breaks)

"Pragmatic" shortcuts = debugging in production = slower.

**"Tests after achieve the same goals - it's spirit not ritual"**

No. Tests-after answer "What does this do?" Tests-first answer "What should this do?"

Tests-after are biased by your implementation. You test what you built, not what's required. You verify remembered edge cases, not discovered ones.

Tests-first force edge case discovery before implementing. Tests-after verify you remembered everything (you didn't).

30 minutes of tests after ‚â† TDD. You get coverage, lose proof tests work.

## Common Rationalizations

| Excuse | Reality |
|--------|---------|
| "Too simple to test" | Simple code breaks. Test takes 30 seconds. |
| "I'll test after" | Tests passing immediately prove nothing. |
| "Tests after achieve same goals" | Tests-after = "what does this do?" Tests-first = "what should this do?" |
| "Already manually tested" | Ad-hoc ‚â† systematic. No record, can't re-run. |
| "Deleting X hours is wasteful" | Sunk cost fallacy. Keeping unverified code is technical debt. |
| "Keep as reference, write tests first" | You'll adapt it. That's testing after. Delete means delete. |
| "Need to explore first" | Fine. Throw away exploration, start with TDD. |
| "Test hard = design unclear" | Listen to test. Hard to test = hard to use. |
| "TDD will slow me down" | TDD faster than debugging. Pragmatic = test-first. |
| "Manual test faster" | Manual doesn't prove edge cases. You'll re-test every change. |
| "Existing code has no tests" | You're improving it. Add tests for existing code. |

## Red Flags - STOP and Start Over

- Code before test
- Test after implementation
- Test passes immediately
- Can't explain why test failed
- Tests added "later"
- Rationalizing "just this once"
- "I already manually tested it"
- "Tests after achieve the same purpose"
- "It's about spirit not ritual"
- "Keep as reference" or "adapt existing code"
- "Already spent X hours, deleting is wasteful"
- "TDD is dogmatic, I'm being pragmatic"
- "This is different because..."

**All of these mean: Delete code. Start over with TDD.**

## Example: Bug Fix

**Bug:** Empty email accepted

**RED**
```typescript
test('rejects empty email', async () => {
  const result = await submitForm({ email: '' });
  expect(result.error).toBe('Email required');
});
```

**Verify RED**
```bash
$ npm test
FAIL: expected 'Email required', got undefined
```

**GREEN**
```typescript
function submitForm(data: FormData) {
  if (!data.email?.trim()) {
    return { error: 'Email required' };
  }
  // ...
}
```

**Verify GREEN**
```bash
$ npm test
PASS
```

**REFACTOR**
Extract validation for multiple fields if needed.

## Verification Checklist

Before marking work complete:

- [ ] Every new function/method has a test
- [ ] Watched each test fail before implementing
- [ ] Each test failed for expected reason (feature missing, not typo)
- [ ] Wrote minimal code to pass each test
- [ ] All tests pass
- [ ] Output pristine (no errors, warnings)
- [ ] Tests use real code (mocks only if unavoidable)
- [ ] Edge cases and errors covered

Can't check all boxes? You skipped TDD. Start over.

## When Stuck

| Problem | Solution |
|---------|----------|
| Don't know how to test | Write wished-for API. Write assertion first. Ask your human partner. |
| Test too complicated | Design too complicated. Simplify interface. |
| Must mock everything | Code too coupled. Use dependency injection. |
| Test setup huge | Extract helpers. Still complex? Simplify design. |

## Debugging Integration

Bug found? Write failing test reproducing it. Follow TDD cycle. Test proves fix and prevents regression.

Never fix bugs without a test.

## Testing Anti-Patterns

When adding mocks or test utilities, read @testing-anti-patterns.md to avoid common pitfalls:
- Testing mock behavior instead of real behavior
- Adding test-only methods to production classes
- Mocking without understanding dependencies

## Final Rule

```
Production code ‚Üí test exists and failed first
Otherwise ‚Üí not TDD
```

No exceptions without your human partner's permission.

---

Base directory for this skill: /home/openclaw/.claude/plugins/cache/claude-plugins-official/superpowers/4.3.1/skills/verification-before-completion

# Verification Before Completion

## Overview

Claiming work is complete without verification is dishonesty, not efficiency.

**Core principle:** Evidence before claims, always.

**Violating the letter of this rule is violating the spirit of this rule.**

## The Iron Law

```
NO COMPLETION CLAIMS WITHOUT FRESH VERIFICATION EVIDENCE
```

If you haven't run the verification command in this message, you cannot claim it passes.

## The Gate Function

```
BEFORE claiming any status or expressing satisfaction:

1. IDENTIFY: What command proves this claim?
2. RUN: Execute the FULL command (fresh, complete)
3. READ: Full output, check exit code, count failures
4. VERIFY: Does output confirm the claim?
   - If NO: State actual status with evidence
   - If YES: State claim WITH evidence
5. ONLY THEN: Make the claim

Skip any step = lying, not verifying
```

## Common Failures

| Claim | Requires | Not Sufficient |
|-------|----------|----------------|
| Tests pass | Test command output: 0 failures | Previous run, "should pass" |
| Linter clean | Linter output: 0 errors | Partial check, extrapolation |
| Build succeeds | Build command: exit 0 | Linter passing, logs look good |
| Bug fixed | Test original symptom: passes | Code changed, assumed fixed |
| Regression test works | Red-green cycle verified | Test passes once |
| Agent completed | VCS diff shows changes | Agent reports "success" |
| Requirements met | Line-by-line checklist | Tests passing |

## Red Flags - STOP

- Using "should", "probably", "seems to"
- Expressing satisfaction before verification ("Great!", "Perfect!", "Done!", etc.)
- About to commit/push/PR without verification
- Trusting agent success reports
- Relying on partial verification
- Thinking "just this once"
- Tired and wanting work over
- **ANY wording implying success without having run verification**

## Rationalization Prevention

| Excuse | Reality |
|--------|---------|
| "Should work now" | RUN the verification |
| "I'm confident" | Confidence ‚â† evidence |
| "Just this once" | No exceptions |
| "Linter passed" | Linter ‚â† compiler |
| "Agent said success" | Verify independently |
| "I'm tired" | Exhaustion ‚â† excuse |
| "Partial check is enough" | Partial proves nothing |
| "Different words so rule doesn't apply" | Spirit over letter |

## Key Patterns

**Tests:**
```
‚úÖ [Run test command] [See: 34/34 pass] "All tests pass"
‚ùå "Should pass now" / "Looks correct"
```

**Regression tests (TDD Red-Green):**
```
‚úÖ Write ‚Üí Run (pass) ‚Üí Revert fix ‚Üí Run (MUST FAIL) ‚Üí Restore ‚Üí Run (pass)
‚ùå "I've written a regression test" (without red-green verification)
```

**Build:**
```
‚úÖ [Run build] [See: exit 0] "Build passes"
‚ùå "Linter passed" (linter doesn't check compilation)
```

**Requirements:**
```
‚úÖ Re-read plan ‚Üí Create checklist ‚Üí Verify each ‚Üí Report gaps or completion
‚ùå "Tests pass, phase complete"
```

**Agent delegation:**
```
‚úÖ Agent reports success ‚Üí Check VCS diff ‚Üí Verify changes ‚Üí Report actual state
‚ùå Trust agent report
```

## Why This Matters

From 24 failure memories:
- your human partner said "I don't believe you" - trust broken
- Undefined functions shipped - would crash
- Missing requirements shipped - incomplete features
- Time wasted on false completion ‚Üí redirect ‚Üí rework
- Violates: "Honesty is a core value. If you lie, you'll be replaced."

## When To Apply

**ALWAYS before:**
- ANY variation of success/completion claims
- ANY expression of satisfaction
- ANY positive statement about work state
- Committing, PR creation, task completion
- Moving to next task
- Delegating to agents

**Rule applies to:**
- Exact phrases
- Paraphrases and synonyms
- Implications of success
- ANY communication suggesting completion/correctness

## The Bottom Line

**No shortcuts for verification.**

Run the command. Read the output. THEN claim the result.

This is non-negotiable.

---

Coverage gap: src/wow/client.ts lines 1159-1170 (sendDnd and sendAfk) are uncovered. Add integration tests in client.test.ts that call handle.sendDnd() and handle.sendAfk() and verify the packets are sent. Must hit 100% coverage. Push when done.

---

Base directory for this skill: /home/openclaw/.claude/plugins/cache/claude-plugins-official/superpowers/4.3.1/skills/test-driven-development

# Test-Driven Development (TDD)

## Overview

Write the test first. Watch it fail. Write minimal code to pass.

**Core principle:** If you didn't watch the test fail, you don't know if it tests the right thing.

**Violating the letter of the rules is violating the spirit of the rules.**

## When to Use

**Always:**
- New features
- Bug fixes
- Refactoring
- Behavior changes

**Exceptions (ask your human partner):**
- Throwaway prototypes
- Generated code
- Configuration files

Thinking "skip TDD just this once"? Stop. That's rationalization.

## The Iron Law

```
NO PRODUCTION CODE WITHOUT A FAILING TEST FIRST
```

Write code before the test? Delete it. Start over.

**No exceptions:**
- Don't keep it as "reference"
- Don't "adapt" it while writing tests
- Don't look at it
- Delete means delete

Implement fresh from tests. Period.

## Red-Green-Refactor

```dot
digraph tdd_cycle {
    rankdir=LR;
    red [label="RED\nWrite failing test", shape=box, style=filled, fillcolor="#ffcccc"];
    verify_red [label="Verify fails\ncorrectly", shape=diamond];
    green [label="GREEN\nMinimal code", shape=box, style=filled, fillcolor="#ccffcc"];
    verify_green [label="Verify passes\nAll green", shape=diamond];
    refactor [label="REFACTOR\nClean up", shape=box, style=filled, fillcolor="#ccccff"];
    next [label="Next", shape=ellipse];

    red -> verify_red;
    verify_red -> green [label="yes"];
    verify_red -> red [label="wrong\nfailure"];
    green -> verify_green;
    verify_green -> refactor [label="yes"];
    verify_green -> green [label="no"];
    refactor -> verify_green [label="stay\ngreen"];
    verify_green -> next;
    next -> red;
}
```

### RED - Write Failing Test

Write one minimal test showing what should happen.

<Good>
```typescript
test('retries failed operations 3 times', async () => {
  let attempts = 0;
  const operation = () => {
    attempts++;
    if (attempts < 3) throw new Error('fail');
    return 'success';
  };

  const result = await retryOperation(operation);

  expect(result).toBe('success');
  expect(attempts).toBe(3);
});
```
Clear name, tests real behavior, one thing
</Good>

<Bad>
```typescript
test('retry works', async () => {
  const mock = jest.fn()
    .mockRejectedValueOnce(new Error())
    .mockRejectedValueOnce(new Error())
    .mockResolvedValueOnce('success');
  await retryOperation(mock);
  expect(mock).toHaveBeenCalledTimes(3);
});
```
Vague name, tests mock not code
</Bad>

**Requirements:**
- One behavior
- Clear name
- Real code (no mocks unless unavoidable)

### Verify RED - Watch It Fail

**MANDATORY. Never skip.**

```bash
npm test path/to/test.test.ts
```

Confirm:
- Test fails (not errors)
- Failure message is expected
- Fails because feature missing (not typos)

**Test passes?** You're testing existing behavior. Fix test.

**Test errors?** Fix error, re-run until it fails correctly.

### GREEN - Minimal Code

Write simplest code to pass the test.

<Good>
```typescript
async function retryOperation<T>(fn: () => Promise<T>): Promise<T> {
  for (let i = 0; i < 3; i++) {
    try {
      return await fn();
    } catch (e) {
      if (i === 2) throw e;
    }
  }
  throw new Error('unreachable');
}
```
Just enough to pass
</Good>

<Bad>
```typescript
async function retryOperation<T>(
  fn: () => Promise<T>,
  options?: {
    maxRetries?: number;
    backoff?: 'linear' | 'exponential';
    onRetry?: (attempt: number) => void;
  }
): Promise<T> {
  // YAGNI
}
```
Over-engineered
</Bad>

Don't add features, refactor other code, or "improve" beyond the test.

### Verify GREEN - Watch It Pass

**MANDATORY.**

```bash
npm test path/to/test.test.ts
```

Confirm:
- Test passes
- Other tests still pass
- Output pristine (no errors, warnings)

**Test fails?** Fix code, not test.

**Other tests fail?** Fix now.

### REFACTOR - Clean Up

After green only:
- Remove duplication
- Improve names
- Extract helpers

Keep tests green. Don't add behavior.

### Repeat

Next failing test for next feature.

## Good Tests

| Quality | Good | Bad |
|---------|------|-----|
| **Minimal** | One thing. "and" in name? Split it. | `test('validates email and domain and whitespace')` |
| **Clear** | Name describes behavior | `test('test1')` |
| **Shows intent** | Demonstrates desired API | Obscures what code should do |

## Why Order Matters

**"I'll write tests after to verify it works"**

Tests written after code pass immediately. Passing immediately proves nothing:
- Might test wrong thing
- Might test implementation, not behavior
- Might miss edge cases you forgot
- You never saw it catch the bug

Test-first forces you to see the test fail, proving it actually tests something.

**"I already manually tested all the edge cases"**

Manual testing is ad-hoc. You think you tested everything but:
- No record of what you tested
- Can't re-run when code changes
- Easy to forget cases under pressure
- "It worked when I tried it" ‚â† comprehensive

Automated tests are systematic. They run the same way every time.

**"Deleting X hours of work is wasteful"**

Sunk cost fallacy. The time is already gone. Your choice now:
- Delete and rewrite with TDD (X more hours, high confidence)
- Keep it and add tests after (30 min, low confidence, likely bugs)

The "waste" is keeping code you can't trust. Working code without real tests is technical debt.

**"TDD is dogmatic, being pragmatic means adapting"**

TDD IS pragmatic:
- Finds bugs before commit (faster than debugging after)
- Prevents regressions (tests catch breaks immediately)
- Documents behavior (tests show how to use code)
- Enables refactoring (change freely, tests catch breaks)

"Pragmatic" shortcuts = debugging in production = slower.

**"Tests after achieve the same goals - it's spirit not ritual"**

No. Tests-after answer "What does this do?" Tests-first answer "What should this do?"

Tests-after are biased by your implementation. You test what you built, not what's required. You verify remembered edge cases, not discovered ones.

Tests-first force edge case discovery before implementing. Tests-after verify you remembered everything (you didn't).

30 minutes of tests after ‚â† TDD. You get coverage, lose proof tests work.

## Common Rationalizations

| Excuse | Reality |
|--------|---------|
| "Too simple to test" | Simple code breaks. Test takes 30 seconds. |
| "I'll test after" | Tests passing immediately prove nothing. |
| "Tests after achieve same goals" | Tests-after = "what does this do?" Tests-first = "what should this do?" |
| "Already manually tested" | Ad-hoc ‚â† systematic. No record, can't re-run. |
| "Deleting X hours is wasteful" | Sunk cost fallacy. Keeping unverified code is technical debt. |
| "Keep as reference, write tests first" | You'll adapt it. That's testing after. Delete means delete. |
| "Need to explore first" | Fine. Throw away exploration, start with TDD. |
| "Test hard = design unclear" | Listen to test. Hard to test = hard to use. |
| "TDD will slow me down" | TDD faster than debugging. Pragmatic = test-first. |
| "Manual test faster" | Manual doesn't prove edge cases. You'll re-test every change. |
| "Existing code has no tests" | You're improving it. Add tests for existing code. |

## Red Flags - STOP and Start Over

- Code before test
- Test after implementation
- Test passes immediately
- Can't explain why test failed
- Tests added "later"
- Rationalizing "just this once"
- "I already manually tested it"
- "Tests after achieve the same purpose"
- "It's about spirit not ritual"
- "Keep as reference" or "adapt existing code"
- "Already spent X hours, deleting is wasteful"
- "TDD is dogmatic, I'm being pragmatic"
- "This is different because..."

**All of these mean: Delete code. Start over with TDD.**

## Example: Bug Fix

**Bug:** Empty email accepted

**RED**
```typescript
test('rejects empty email', async () => {
  const result = await submitForm({ email: '' });
  expect(result.error).toBe('Email required');
});
```

**Verify RED**
```bash
$ npm test
FAIL: expected 'Email required', got undefined
```

**GREEN**
```typescript
function submitForm(data: FormData) {
  if (!data.email?.trim()) {
    return { error: 'Email required' };
  }
  // ...
}
```

**Verify GREEN**
```bash
$ npm test
PASS
```

**REFACTOR**
Extract validation for multiple fields if needed.

## Verification Checklist

Before marking work complete:

- [ ] Every new function/method has a test
- [ ] Watched each test fail before implementing
- [ ] Each test failed for expected reason (feature missing, not typo)
- [ ] Wrote minimal code to pass each test
- [ ] All tests pass
- [ ] Output pristine (no errors, warnings)
- [ ] Tests use real code (mocks only if unavoidable)
- [ ] Edge cases and errors covered

Can't check all boxes? You skipped TDD. Start over.

## When Stuck

| Problem | Solution |
|---------|----------|
| Don't know how to test | Write wished-for API. Write assertion first. Ask your human partner. |
| Test too complicated | Design too complicated. Simplify interface. |
| Must mock everything | Code too coupled. Use dependency injection. |
| Test setup huge | Extract helpers. Still complex? Simplify design. |

## Debugging Integration

Bug found? Write failing test reproducing it. Follow TDD cycle. Test proves fix and prevents regression.

Never fix bugs without a test.

## Testing Anti-Patterns

When adding mocks or test utilities, read @testing-anti-patterns.md to avoid common pitfalls:
- Testing mock behavior instead of real behavior
- Adding test-only methods to production classes
- Mocking without understanding dependencies

## Final Rule

```
Production code ‚Üí test exists and failed first
Otherwise ‚Üí not TDD
```

No exceptions without your human partner's permission.

---

You are a senior security engineer conducting a focused security review of the changes on this branch.

GIT STATUS:

```
On branch feat/dnd-afk-commands
Your branch is up to date with 'origin/feat/dnd-afk-commands'.

Untracked files:
  (use "git add <file>..." to include in what will be committed)
	docs/plans/2026-02-19-reconnect-auth-design.md
	docs/plans/2026-02-19-reconnect-auth-plan.md

nothing added to commit but untracked files present (use "git add" to track)
```

FILES MODIFIED:

```
.claude/skills/tuicraft/SKILL.md
README.md
docs/manual.md
src/cli/help.ts
src/daemon/commands.test.ts
src/daemon/commands.ts
src/daemon/start.test.ts
src/test/mock-handle.ts
src/ui/tui.test.ts
src/ui/tui.ts
src/wow/client.test.ts
src/wow/client.ts
src/wow/protocol/chat.test.ts
src/wow/protocol/opcodes.ts
```

COMMITS:

```
commit e29be55087fab32a7d0e7e3af8b3b201bbce0faf
Author: OpenClaw <openclaw@vararu.org>
Date:   Sun Mar 1 00:32:08 2026 +0000

    test: Cover sendDnd and sendAfk in client integration tests
    
    Add mock-world-server echo tests for both methods, matching the
    existing pattern used by sendSay/sendYell/sendEmote.
    
    Entire-Checkpoint: c4669d718bdc

commit f635a553c0753557eabe2f157eb4796b6cc79210
Author: OpenClaw <openclaw@vararu.org>
Date:   Sun Mar 1 00:22:03 2026 +0000

    feat: Add /dnd and /afk status commands
    
    Send CMSG_MESSAGECHAT with ChatType.DND (0x18) and ChatType.AFK
    (0x17) to toggle player status flags on the server. Follows the
    same pattern as say/yell/emote ‚Äî no separate opcode needed.
    
    Entire-Checkpoint: 00f2e1f2a4cc
```

DIFF CONTENT:

```
diff --git a/.claude/skills/tuicraft/SKILL.md b/.claude/skills/tuicraft/SKILL.md
index 5336154..bfbe326 100644
--- a/.claude/skills/tuicraft/SKILL.md
+++ b/.claude/skills/tuicraft/SKILL.md
@@ -25,6 +25,8 @@ Slash commands work too:
 
     tuicraft send "/raid message"         # raid chat
     tuicraft send "/e waves hello"        # text emote
+    tuicraft send "/dnd busy right now"   # toggle DND status
+    tuicraft send "/afk grabbing coffee"  # toggle AFK status
     tuicraft send "/1 message"            # channel 1
     tuicraft send "/2 message"            # channel 2
 
diff --git a/README.md b/README.md
index 705dcdb..6cbf2e3 100644
--- a/README.md
+++ b/README.md
@@ -141,7 +141,7 @@ that the official game client does.
 | Server broadcast messages               | ‚ùå     |
 | Chat restricted / wrong faction notices | ‚ùå     |
 | Text emotes (`/e`, `/emote`)            | ‚úÖ     |
-| DND / AFK status                        | ‚ùå     |
+| DND / AFK status                        | ‚úÖ     |
 
 ### üë• Social
 
diff --git a/docs/manual.md b/docs/manual.md
index 02a2c4b..bc04c71 100644
--- a/docs/manual.md
+++ b/docs/manual.md
@@ -122,6 +122,8 @@ When running in TUI mode, the following slash commands are available:
 | `/p` _msg_                   | Party chat                  |
 | `/raid` _msg_                | Raid chat                   |
 | `/e` _msg_                   | Text emote                  |
+| `/dnd` [_msg_]               | Toggle Do Not Disturb       |
+| `/afk` [_msg_]               | Toggle Away From Keyboard   |
 | `/1` _msg_                   | Channel 1 (usually General) |
 | `/2` _msg_                   | Channel 2 (usually Trade)   |
 | `/who` _query_               | Who search                  |
diff --git a/src/cli/help.ts b/src/cli/help.ts
index 8aa9ee2..f810fa9 100644
--- a/src/cli/help.ts
+++ b/src/cli/help.ts
@@ -37,6 +37,8 @@ SETUP FLAGS
 
 INTERACTIVE COMMANDS (TUI mode)
   /s, /y, /w, /g, /p, /raid, /e, /1, /2  Chat commands
+  /dnd [message]  Toggle Do Not Disturb status
+  /afk [message]  Toggle Away From Keyboard status
   /r              Reply to last whisper
   /who [filter]   Who search
   /invite <name>  Invite player to group
diff --git a/src/daemon/commands.test.ts b/src/daemon/commands.test.ts
index 67336f2..1007cf4 100644
--- a/src/daemon/commands.test.ts
+++ b/src/daemon/commands.test.ts
@@ -81,6 +81,34 @@ describe("parseIpcCommand", () => {
     });
   });
 
+  test("DND", () => {
+    expect(parseIpcCommand("DND busy right now")).toEqual({
+      type: "dnd",
+      message: "busy right now",
+    });
+  });
+
+  test("DND without message", () => {
+    expect(parseIpcCommand("DND")).toEqual({
+      type: "dnd",
+      message: "",
+    });
+  });
+
+  test("AFK", () => {
+    expect(parseIpcCommand("AFK grabbing coffee")).toEqual({
+      type: "afk",
+      message: "grabbing coffee",
+    });
+  });
+
+  test("AFK without message", () => {
+    expect(parseIpcCommand("AFK")).toEqual({
+      type: "afk",
+      message: "",
+    });
+  });
+
   test("WHISPER", () => {
     expect(parseIpcCommand("WHISPER Xiara follow me")).toEqual({
       type: "whisper",
@@ -216,6 +244,20 @@ describe("parseIpcCommand", () => {
     });
   });
 
+  test("slash /dnd maps to dnd", () => {
+    expect(parseIpcCommand("/dnd busy")).toEqual({
+      type: "dnd",
+      message: "busy",
+    });
+  });
+
+  test("slash /afk maps to afk", () => {
+    expect(parseIpcCommand("/afk brb")).toEqual({
+      type: "afk",
+      message: "brb",
+    });
+  });
+
   test("slash /who maps to who with filter", () => {
     expect(parseIpcCommand("/who mage")).toEqual({
       type: "who",
@@ -292,8 +334,6 @@ describe("parseIpcCommand", () => {
       ["GPROMOTE Foo", "Guild management"],
       ["MAIL", "Mail"],
       ["ROLL", "Random roll"],
-      ["DND", "Player status"],
-      ["AFK", "Player status"],
     ] as const;
 
     for (const [input, feature] of cases) {
@@ -498,6 +538,42 @@ describe("dispatchCommand", () => {
     expect(socket.written()).toBe("OK\n\n");
   });
 
+  test("dnd calls sendDnd and writes OK", async () => {
+    const handle = createMockHandle();
+    const events = new RingBuffer<EventEntry>(10);
+    const socket = createMockSocket();
+    const cleanup = jest.fn();
+
+    await dispatchCommand(
+      { type: "dnd", message: "busy" },
+      handle,
+      events,
+      socket,
+      cleanup,
+    );
+
+    expect(handle.sendDnd).toHaveBeenCalledWith("busy");
+    expect(socket.written()).toBe("OK\n\n");
+  });
+
+  test("afk calls sendAfk and writes OK", async () => {
+    const handle = createMockHandle();
+    const events = new RingBuffer<EventEntry>(10);
+    const socket = createMockSocket();
+    const cleanup = jest.fn();
+
+    await dispatchCommand(
+      { type: "afk", message: "grabbing coffee" },
+      handle,
+      events,
+      socket,
+      cleanup,
+    );
+
+    expect(handle.sendAfk).toHaveBeenCalledWith("grabbing coffee");
+    expect(socket.written()).toBe("OK\n\n");
+  });
+
   test("whisper calls sendWhisper and writes OK", async () => {
     const handle = createMockHandle();
     const events = new RingBuffer<EventEntry>(10);
@@ -1699,6 +1775,20 @@ describe("IPC round-trip", () => {
     expect(handle.sendEmote).toHaveBeenCalledWith("waves hello");
   });
 
+  test("DND returns OK and calls handle", async () => {
+    startTestServer();
+    const lines = await sendToSocket("DND busy right now", sockPath);
+    expect(lines).toEqual(["OK"]);
+    expect(handle.sendDnd).toHaveBeenCalledWith("busy right now");
+  });
+
+  test("AFK returns OK and calls handle", async () => {
+    startTestServer();
+    const lines = await sendToSocket("AFK grabbing coffee", sockPath);
+    expect(lines).toEqual(["OK"]);
+    expect(handle.sendAfk).toHaveBeenCalledWith("grabbing coffee");
+  });
+
   test("WHISPER returns OK", async () => {
     startTestServer();
     const lines = await sendToSocket("WHISPER Xiara hey", sockPath);
diff --git a/src/daemon/commands.ts b/src/daemon/commands.ts
index c49c3f2..839586f 100644
--- a/src/daemon/commands.ts
+++ b/src/daemon/commands.ts
@@ -38,6 +38,8 @@ export type IpcCommand =
   | { type: "guild"; message: string }
   | { type: "party"; message: string }
   | { type: "emote"; message: string }
+  | { type: "dnd"; message: string }
+  | { type: "afk"; message: string }
   | { type: "whisper"; target: string; message: string }
   | { type: "read" }
   | { type: "read_json" }
@@ -70,6 +72,8 @@ export function parseIpcCommand(line: string): IpcCommand | undefined {
       case "guild":
       case "party":
       case "emote":
+      case "dnd":
+      case "afk":
         return parsed;
       case "whisper":
         return parsed;
@@ -107,13 +111,17 @@ export function parseIpcCommand(line: string): IpcCommand | undefined {
     case "GUILD":
     case "PARTY":
     case "EMOTE":
+    case "DND":
+    case "AFK":
       return {
         type: verb.toLowerCase() as
           | "say"
           | "yell"
           | "guild"
           | "party"
-          | "emote",
+          | "emote"
+          | "dnd"
+          | "afk",
         message: rest,
       };
     case "WHISPER": {
@@ -185,9 +193,6 @@ export function parseIpcCommand(line: string): IpcCommand | undefined {
       return { type: "unimplemented", feature: "Mail" };
     case "ROLL":
       return { type: "unimplemented", feature: "Random roll" };
-    case "DND":
-    case "AFK":
-      return { type: "unimplemented", feature: "Player status" };
     default:
       return line ? { type: "chat", message: line } : undefined;
   }
@@ -256,6 +261,14 @@ export async function dispatchCommand(
       handle.sendEmote(cmd.message);
       writeLines(socket, ["OK"]);
       return false;
+    case "dnd":
+      handle.sendDnd(cmd.message);
+      writeLines(socket, ["OK"]);
+      return false;
+    case "afk":
+      handle.sendAfk(cmd.message);
+      writeLines(socket, ["OK"]);
+      return false;
     case "whisper":
       handle.sendWhisper(cmd.target, cmd.message);
       writeLines(socket, ["OK"]);
diff --git a/src/daemon/start.test.ts b/src/daemon/start.test.ts
index 21b51bf..efd91c5 100644
--- a/src/daemon/start.test.ts
+++ b/src/daemon/start.test.ts
@@ -51,6 +51,8 @@ function makeMockClient(): {
         sendParty: jest.fn(),
         sendRaid: jest.fn(),
         sendEmote: jest.fn(),
+        sendDnd: jest.fn(),
+        sendAfk: jest.fn(),
         sendWhisper: jest.fn(),
         sendChannel: jest.fn(),
         getChannel: jest.fn(),
diff --git a/src/test/mock-handle.ts b/src/test/mock-handle.ts
index a74be9e..3df3f50 100644
--- a/src/test/mock-handle.ts
+++ b/src/test/mock-handle.ts
@@ -38,6 +38,8 @@ export function createMockHandle(): WorldHandle & {
     sendParty: jest.fn(),
     sendRaid: jest.fn(),
     sendEmote: jest.fn(),
+    sendDnd: jest.fn(),
+    sendAfk: jest.fn(),
     sendChannel: jest.fn(),
     getChannel: jest.fn(),
     who: jest.fn(async () => []),
diff --git a/src/ui/tui.test.ts b/src/ui/tui.test.ts
index ce1e4d2..c085400 100644
--- a/src/ui/tui.test.ts
+++ b/src/ui/tui.test.ts
@@ -279,16 +279,28 @@ describe("parseCommand", () => {
         feature: "Random roll",
       });
     });
-    test("/dnd returns unimplemented", () => {
+    test("/dnd sends dnd with message", () => {
+      expect(parseCommand("/dnd busy right now")).toEqual({
+        type: "dnd",
+        message: "busy right now",
+      });
+    });
+    test("/dnd sends dnd with empty message", () => {
       expect(parseCommand("/dnd")).toEqual({
-        type: "unimplemented",
-        feature: "Player status",
+        type: "dnd",
+        message: "",
       });
     });
-    test("/afk returns unimplemented", () => {
+    test("/afk sends afk with message", () => {
+      expect(parseCommand("/afk grabbing coffee")).toEqual({
+        type: "afk",
+        message: "grabbing coffee",
+      });
+    });
+    test("/afk sends afk with empty message", () => {
       expect(parseCommand("/afk")).toEqual({
-        type: "unimplemented",
-        feature: "Player status",
+        type: "afk",
+        message: "",
       });
     });
     test("/e sends emote", () => {
@@ -452,7 +464,7 @@ describe("startTui", () => {
     await done;
   });
 
-  test("dispatches yell, guild, party, raid, emote commands", async () => {
+  test("dispatches yell, guild, party, raid, emote, dnd, afk commands", async () => {
     const handle = createMockHandle();
     const input = new PassThrough();
 
@@ -462,6 +474,8 @@ describe("startTui", () => {
     writeLine(input, "/p party msg");
     writeLine(input, "/raid pull now");
     writeLine(input, "/e waves hello");
+    writeLine(input, "/dnd busy");
+    writeLine(input, "/afk coffee break");
     await flush();
 
     expect(handle.sendYell).toHaveBeenCalledWith("LOUD");
@@ -469,6 +483,8 @@ describe("startTui", () => {
     expect(handle.sendParty).toHaveBeenCalledWith("party msg");
     expect(handle.sendRaid).toHaveBeenCalledWith("pull now");
     expect(handle.sendEmote).toHaveBeenCalledWith("waves hello");
+    expect(handle.sendDnd).toHaveBeenCalledWith("busy");
+    expect(handle.sendAfk).toHaveBeenCalledWith("coffee break");
 
     input.end();
     await done;
diff --git a/src/ui/tui.ts b/src/ui/tui.ts
index 97934c7..ef6d6fa 100644
--- a/src/ui/tui.ts
+++ b/src/ui/tui.ts
@@ -22,6 +22,8 @@ export type Command =
   | { type: "party"; message: string }
   | { type: "raid"; message: string }
   | { type: "emote"; message: string }
+  | { type: "dnd"; message: string }
+  | { type: "afk"; message: string }
   | { type: "whisper"; target: string; message: string }
   | { type: "reply"; message: string }
   | { type: "channel"; target: string; message: string }
@@ -130,8 +132,9 @@ export function parseCommand(input: string): Command {
     case "/roll":
       return { type: "unimplemented", feature: "Random roll" };
     case "/dnd":
+      return { type: "dnd", message: rest };
     case "/afk":
-      return { type: "unimplemented", feature: "Player status" };
+      return { type: "afk", message: rest };
     case "/e":
     case "/emote":
       return { type: "emote", message: rest };
@@ -524,6 +527,12 @@ export async function executeCommand(
     case "emote":
       state.handle.sendEmote(cmd.message);
       break;
+    case "dnd":
+      state.handle.sendDnd(cmd.message);
+      break;
+    case "afk":
+      state.handle.sendAfk(cmd.message);
+      break;
     case "whisper":
       state.handle.sendWhisper(cmd.target, cmd.message);
       state.lastWhisperFrom = cmd.target;
diff --git a/src/wow/client.test.ts b/src/wow/client.test.ts
index e529890..fafe211 100644
--- a/src/wow/client.test.ts
+++ b/src/wow/client.test.ts
@@ -786,6 +786,44 @@ describe("world error paths", () => {
     }
   });
 
+  test("sendDnd sends message and receives echo", async () => {
+    const ws = await startMockWorldServer();
+    try {
+      const handle = await worldSession(
+        { ...base, host: "127.0.0.1", port: ws.port },
+        fakeAuth(ws.port),
+      );
+      const received = new Promise<ChatMessage>((r) => handle.onMessage(r));
+      handle.sendDnd("busy right now");
+      const msg = await received;
+      expect(msg.type).toBe(ChatType.DND);
+      expect(msg.message).toBe("busy right now");
+      handle.close();
+      await handle.closed;
+    } finally {
+      ws.stop();
+    }
+  });
+
+  test("sendAfk sends message and receives echo", async () => {
+    const ws = await startMockWorldServer();
+    try {
+      const handle = await worldSession(
+        { ...base, host: "127.0.0.1", port: ws.port },
+        fakeAuth(ws.port),
+      );
+      const received = new Promise<ChatMessage>((r) => handle.onMessage(r));
+      handle.sendAfk("grabbing coffee");
+      const msg = await received;
+      expect(msg.type).toBe(ChatType.AFK);
+      expect(msg.message).toBe("grabbing coffee");
+      handle.close();
+      await handle.closed;
+    } finally {
+      ws.stop();
+    }
+  });
+
   test("sendChannel sends message and receives echo", async () => {
     const ws = await startMockWorldServer();
     try {
diff --git a/src/wow/client.ts b/src/wow/client.ts
index b17a443..dfc7884 100644
--- a/src/wow/client.ts
+++ b/src/wow/client.ts
@@ -166,6 +166,8 @@ export type WorldHandle = {
   sendParty(message: string): void;
   sendRaid(message: string): void;
   sendEmote(message: string): void;
+  sendDnd(message: string): void;
+  sendAfk(message: string): void;
   sendChannel(channel: string, message: string): void;
   getChannel(index: number): string | undefined;
   who(opts?: {
@@ -1154,6 +1156,20 @@ export function worldSession(
             buildChatMessage(ChatType.EMOTE, lang, message),
           );
         },
+        sendDnd(message) {
+          sendPacket(
+            conn,
+            GameOpcode.CMSG_MESSAGE_CHAT,
+            buildChatMessage(ChatType.DND, lang, message),
+          );
+        },
+        sendAfk(message) {
+          sendPacket(
+            conn,
+            GameOpcode.CMSG_MESSAGE_CHAT,
+            buildChatMessage(ChatType.AFK, lang, message),
+          );
+        },
         sendChannel(channel, message) {
           conn.lastChatMode = { type: "channel", channel };
           sendPacket(
diff --git a/src/wow/protocol/chat.test.ts b/src/wow/protocol/chat.test.ts
index 21d5d65..b0360c1 100644
--- a/src/wow/protocol/chat.test.ts
+++ b/src/wow/protocol/chat.test.ts
@@ -159,6 +159,22 @@ describe("buildChatMessage", () => {
     expect(r.uint32LE()).toBe(Language.COMMON);
     expect(r.cString()).toBe("hello guild");
   });
+
+  test("builds a DND message", () => {
+    const body = buildChatMessage(ChatType.DND, Language.COMMON, "busy");
+    const r = new PacketReader(body);
+    expect(r.uint32LE()).toBe(ChatType.DND);
+    expect(r.uint32LE()).toBe(Language.COMMON);
+    expect(r.cString()).toBe("busy");
+  });
+
+  test("builds an AFK message", () => {
+    const body = buildChatMessage(ChatType.AFK, Language.COMMON, "brb");
+    const r = new PacketReader(body);
+    expect(r.uint32LE()).toBe(ChatType.AFK);
+    expect(r.uint32LE()).toBe(Language.COMMON);
+    expect(r.cString()).toBe("brb");
+  });
 });
 
 describe("buildNameQuery / parseNameQueryResponse", () => {
diff --git a/src/wow/protocol/opcodes.ts b/src/wow/protocol/opcodes.ts
index c05c87a..6485f94 100644
--- a/src/wow/protocol/opcodes.ts
+++ b/src/wow/protocol/opcodes.ts
@@ -653,6 +653,8 @@ export const ChatType = {
   WHISPER_INFORM: 0x09,
   EMOTE: 0x0a,
   CHANNEL: 0x11,
+  AFK: 0x17,
+  DND: 0x18,
   RAID_LEADER: 0x27,
   RAID_WARNING: 0x28,
   BATTLEGROUND: 0x2c,
```

Review the complete diff above. This contains all code changes in the PR.


OBJECTIVE:
Perform a security-focused code review to identify HIGH-CONFIDENCE security vulnerabilities that could have real exploitation potential. This is not a general code review - focus ONLY on security implications newly added by this PR. Do not comment on existing security concerns.

CRITICAL INSTRUCTIONS:
1. MINIMIZE FALSE POSITIVES: Only flag issues where you're >80% confident of actual exploitability
2. AVOID NOISE: Skip theoretical issues, style concerns, or low-impact findings
3. FOCUS ON IMPACT: Prioritize vulnerabilities that could lead to unauthorized access, data breaches, or system compromise
4. EXCLUSIONS: Do NOT report the following issue types:
   - Denial of Service (DOS) vulnerabilities, even if they allow service disruption
   - Secrets or sensitive data stored on disk (these are handled by other processes)
   - Rate limiting or resource exhaustion issues

SECURITY CATEGORIES TO EXAMINE:

**Input Validation Vulnerabilities:**
- SQL injection via unsanitized user input
- Command injection in system calls or subprocesses
- XXE injection in XML parsing
- Template injection in templating engines
- NoSQL injection in database queries
- Path traversal in file operations

**Authentication & Authorization Issues:**
- Authentication bypass logic
- Privilege escalation paths
- Session management flaws
- JWT token vulnerabilities
- Authorization logic bypasses

**Crypto & Secrets Management:**
- Hardcoded API keys, passwords, or tokens
- Weak cryptographic algorithms or implementations
- Improper key storage or management
- Cryptographic randomness issues
- Certificate validation bypasses

**Injection & Code Execution:**
- Remote code execution via deseralization
- Pickle injection in Python
- YAML deserialization vulnerabilities
- Eval injection in dynamic code execution
- XSS vulnerabilities in web applications (reflected, stored, DOM-based)

**Data Exposure:**
- Sensitive data logging or storage
- PII handling violations
- API endpoint data leakage
- Debug information exposure

Additional notes:
- Even if something is only exploitable from the local network, it can still be a HIGH severity issue

ANALYSIS METHODOLOGY:

Phase 1 - Repository Context Research (Use file search tools):
- Identify existing security frameworks and libraries in use
- Look for established secure coding patterns in the codebase
- Examine existing sanitization and validation patterns
- Understand the project's security model and threat model

Phase 2 - Comparative Analysis:
- Compare new code changes against existing security patterns
- Identify deviations from established secure practices
- Look for inconsistent security implementations
- Flag code that introduces new attack surfaces

Phase 3 - Vulnerability Assessment:
- Examine each modified file for security implications
- Trace data flow from user inputs to sensitive operations
- Look for privilege boundaries being crossed unsafely
- Identify injection points and unsafe deserialization

REQUIRED OUTPUT FORMAT:

You MUST output your findings in markdown. The markdown output should contain the file, line number, severity, category (e.g. `sql_injection` or `xss`), description, exploit scenario, and fix recommendation.

For example:

# Vuln 1: XSS: `foo.py:42`

* Severity: High
* Description: User input from `username` parameter is directly interpolated into HTML without escaping, allowing reflected XSS attacks
* Exploit Scenario: Attacker crafts URL like /bar?q=<script>alert(document.cookie)</script> to execute JavaScript in victim's browser, enabling session hijacking or data theft
* Recommendation: Use Flask's escape() function or Jinja2 templates with auto-escaping enabled for all user inputs rendered in HTML

SEVERITY GUIDELINES:
- **HIGH**: Directly exploitable vulnerabilities leading to RCE, data breach, or authentication bypass
- **MEDIUM**: Vulnerabilities requiring specific conditions but with significant impact
- **LOW**: Defense-in-depth issues or lower-impact vulnerabilities

CONFIDENCE SCORING:
- 0.9-1.0: Certain exploit path identified, tested if possible
- 0.8-0.9: Clear vulnerability pattern with known exploitation methods
- 0.7-0.8: Suspicious pattern requiring specific conditions to exploit
- Below 0.7: Don't report (too speculative)

FINAL REMINDER:
Focus on HIGH and MEDIUM findings only. Better to miss some theoretical issues than flood the report with false positives. Each finding should be something a security engineer would confidently raise in a PR review.

FALSE POSITIVE FILTERING:

> You do not need to run commands to reproduce the vulnerability, just read the code to determine if it is a real vulnerability. Do not use the bash tool or write to any files.
>
> HARD EXCLUSIONS - Automatically exclude findings matching these patterns:
> 1. Denial of Service (DOS) vulnerabilities or resource exhaustion attacks.
> 2. Secrets or credentials stored on disk if they are otherwise secured.
> 3. Rate limiting concerns or service overload scenarios.
> 4. Memory consumption or CPU exhaustion issues.
> 5. Lack of input validation on non-security-critical fields without proven security impact.
> 6. Input sanitization concerns for GitHub Action workflows unless they are clearly triggerable via untrusted input.
> 7. A lack of hardening measures. Code is not expected to implement all security best practices, only flag concrete vulnerabilities.
> 8. Race conditions or timing attacks that are theoretical rather than practical issues. Only report a race condition if it is concretely problematic.
> 9. Vulnerabilities related to outdated third-party libraries. These are managed separately and should not be reported here.
> 10. Memory safety issues such as buffer overflows or use-after-free-vulnerabilities are impossible in rust. Do not report memory safety issues in rust or any other memory safe languages.
> 11. Files that are only unit tests or only used as part of running tests.
> 12. Log spoofing concerns. Outputting un-sanitized user input to logs is not a vulnerability.
> 13. SSRF vulnerabilities that only control the path. SSRF is only a concern if it can control the host or protocol.
> 14. Including user-controlled content in AI system prompts is not a vulnerability.
> 15. Regex injection. Injecting untrusted content into a regex is not a vulnerability.
> 16. Regex DOS concerns.
> 16. Insecure documentation. Do not report any findings in documentation files such as markdown files.
> 17. A lack of audit logs is not a vulnerability.
>
> PRECEDENTS -
> 1. Logging high value secrets in plaintext is a vulnerability. Logging URLs is assumed to be safe.
> 2. UUIDs can be assumed to be unguessable and do not need to be validated.
> 3. Environment variables and CLI flags are trusted values. Attackers are generally not able to modify them in a secure environment. Any attack that relies on controlling an environment variable is invalid.
> 4. Resource management issues such as memory or file descriptor leaks are not valid.
> 5. Subtle or low impact web vulnerabilities such as tabnabbing, XS-Leaks, prototype pollution, and open redirects should not be reported unless they are extremely high confidence.
> 6. React and Angular are generally secure against XSS. These frameworks do not need to sanitize or escape user input unless it is using dangerouslySetInnerHTML, bypassSecurityTrustHtml, or similar methods. Do not report XSS vulnerabilities in React or Angular components or tsx files unless they are using unsafe methods.
> 7. Most vulnerabilities in github action workflows are not exploitable in practice. Before validating a github action workflow vulnerability ensure it is concrete and has a very specific attack path.
> 8. A lack of permission checking or authentication in client-side JS/TS code is not a vulnerability. Client-side code is not trusted and does not need to implement these checks, they are handled on the server-side. The same applies to all flows that send untrusted data to the backend, the backend is responsible for validating and sanitizing all inputs.
> 9. Only include MEDIUM findings if they are obvious and concrete issues.
> 10. Most vulnerabilities in ipython notebooks (*.ipynb files) are not exploitable in practice. Before validating a notebook vulnerability ensure it is concrete and has a very specific attack path where untrusted input can trigger the vulnerability.
> 11. Logging non-PII data is not a vulnerability even if the data may be sensitive. Only report logging vulnerabilities if they expose sensitive information such as secrets, passwords, or personally identifiable information (PII).
> 12. Command injection vulnerabilities in shell scripts are generally not exploitable in practice since shell scripts generally do not run with untrusted user input. Only report command injection vulnerabilities in shell scripts if they are concrete and have a very specific attack path for untrusted input.
>
> SIGNAL QUALITY CRITERIA - For remaining findings, assess:
> 1. Is there a concrete, exploitable vulnerability with a clear attack path?
> 2. Does this represent a real security risk vs theoretical best practice?
> 3. Are there specific code locations and reproduction steps?
> 4. Would this finding be actionable for a security team?
>
> For each finding, assign a confidence score from 1-10:
> - 1-3: Low confidence, likely false positive or noise
> - 4-6: Medium confidence, needs investigation
> - 7-10: High confidence, likely true vulnerability

START ANALYSIS:

Begin your analysis now. Do this in 3 steps:

1. Use a sub-task to identify vulnerabilities. Use the repository exploration tools to understand the codebase context, then analyze the PR changes for security implications. In the prompt for this sub-task, include all of the above.
2. Then for each vulnerability identified by the above sub-task, create a new sub-task to filter out false-positives. Launch these sub-tasks as parallel sub-tasks. In the prompt for these sub-tasks, include everything in the "FALSE POSITIVE FILTERING" instructions.
3. Filter out any vulnerabilities where the sub-task reported a confidence less than 8.

Your final reply must contain the markdown report and nothing else.

---

You are an expert code reviewer. Follow these steps:

      1. If no PR number is provided in the args, run `gh pr list` to show open PRs
      2. If a PR number is provided, run `gh pr view <number>` to get PR details
      3. Run `gh pr diff <number>` to get the diff
      4. Analyze the changes and provide a thorough code review that includes:
         - Overview of what the PR does
         - Analysis of code quality and style
         - Specific suggestions for improvements
         - Any potential issues or risks

      Keep your review concise but thorough. Focus on:
      - Code correctness
      - Following project conventions
      - Performance implications
      - Test coverage
      - Security considerations

      Format your review with clear sections and bullet points.

      PR number:

---

# Simplify: Code Review and Cleanup

Review all changed files for reuse, quality, and efficiency. Fix any issues found.

## Phase 1: Identify Changes

Run `git diff` (or `git diff HEAD` if there are staged changes) to see what changed. If there are no git changes, review the most recently modified files that the user mentioned or that you edited earlier in this conversation.

## Phase 2: Launch Three Review Agents in Parallel

Use the Agent tool to launch all three agents concurrently in a single message. Pass each agent the full diff so it has the complete context.

### Agent 1: Code Reuse Review

For each change:

1. **Search for existing utilities and helpers** that could replace newly written code. Use Grep to find similar patterns elsewhere in the codebase ‚Äî common locations are utility directories, shared modules, and files adjacent to the changed ones.
2. **Flag any new function that duplicates existing functionality.** Suggest the existing function to use instead.
3. **Flag any inline logic that could use an existing utility** ‚Äî hand-rolled string manipulation, manual path handling, custom environment checks, ad-hoc type guards, and similar patterns are common candidates.

### Agent 2: Code Quality Review

Review the same changes for hacky patterns:

1. **Redundant state**: state that duplicates existing state, cached values that could be derived, observers/effects that could be direct calls
2. **Parameter sprawl**: adding new parameters to a function instead of generalizing or restructuring existing ones
3. **Copy-paste with slight variation**: near-duplicate code blocks that should be unified with a shared abstraction
4. **Leaky abstractions**: exposing internal details that should be encapsulated, or breaking existing abstraction boundaries
5. **Stringly-typed code**: using raw strings where constants, enums (string unions), or branded types already exist in the codebase

### Agent 3: Efficiency Review

Review the same changes for efficiency:

1. **Unnecessary work**: redundant computations, repeated file reads, duplicate network/API calls, N+1 patterns
2. **Missed concurrency**: independent operations run sequentially when they could run in parallel
3. **Hot-path bloat**: new blocking work added to startup or per-request/per-render hot paths
4. **Unnecessary existence checks**: pre-checking file/resource existence before operating (TOCTOU anti-pattern) ‚Äî operate directly and handle the error
5. **Memory**: unbounded data structures, missing cleanup, event listener leaks
6. **Overly broad operations**: reading entire files when only a portion is needed, loading all items when filtering for one

## Phase 3: Fix Issues

Wait for all three agents to complete. Aggregate their findings and fix each issue directly. If a finding is a false positive or not worth addressing, note it and move on ‚Äî do not argue with the finding, just skip it.

When done, briefly summarize what was fixed (or confirm the code was already clean).